'''
Created on Aug 31, 2017

A collection of methods for parsing files generated by eCLIP pipelines.

@author: byee4
'''

import pybedtools
import os
import functools
import glob
import pandas as pd

REGIONS = ['noncoding_exon', '3utr', '5utr', 'intron', 'noncoding_intron',
           'CDS', 'intergenic', '5utr_and_3utr']

ANNOTATED_BED_HEADERS_ERIC = [
    'chrom', 'start', 'end', 'pv', 'fc', 'strand', 'annotation', 'gene'
]

ANNOTATED_BED_HEADERS_BRIAN = [
    'chrom', 'start', 'end', 'pv', 'fc', 'strand', 'gene', 'name',
    'region', 'type', 'all_overlaps'
]

def split_single_cols(df, col, sep='|'):
    """
    Splits a df['col'] into two separated by 'sep' (specifically one whose
    delimiter separates log2 fold change | log10 p-value).

    This is used to parse tab separated files that also need to be split
    on another character (see: *ReadsByLoc_combined.csv.l2fcwithpval_enr.csv)

    Parameters
    ----------
    df : pandas.DataFrame
        dataframe of l2fcwithpval_enr file
    col : basestring
    sep : basestring

    Returns
    -------
    df : pandas.DataFrame
    """
    df["{} l2fc".format(col.split(sep)[1])], \
    df["{} l10p".format(col.split(sep)[1])] = zip(
        *df[col].map(lambda x: x.split(sep))
    )
    return df


def split_l2fcwithpval_enr(df, discard = True):
    """
    Splits a dataframe into its l2fc and log10 pvalue

    Parameters
    ----------
    df : pandas.DataFrame
        dataframe of l2fcwithpval_enr file
    discard : bool
        if True, discard the original column.
        if False, keep the original column.

    Returns
    -------
    df : pandas.DataFrame
    """

    for col in df.columns:
        df = split_single_cols(df, col)
        if discard:
            del df[col]
    return df


def scatter_matrix(ip_l2fc, inp_reads_by_loc):
    """
    Inner joins the ip l2fc and input reads by loc files

    Parameters
    ----------
    ip_l2fc : basestring
        "IP*_ReadsByLoc_combined.csv.l2fcwithpval_enr.csv"
    inp_reads_by_loc : basestring
        "INPUT*reads_by_loc.csv"

    Returns
    -------
    x : pandas.DataFrame
        intersection of fold-enrichment and input reads covering each gene.
    """

    plot_x = pd.read_table(
        inp_reads_by_loc,
        index_col=0,
    )

    plot_y = pd.read_table(
        ip_l2fc,
        index_col=0,
    )
    plot_y = split_l2fcwithpval_enr(plot_y)

    x = pd.merge(plot_x, plot_y, how='inner', left_index=True,
                 right_index=True)
    return x


def filter_input_norm_as_df(fn, l10p, l2fc, l10p_col=3, l2fc_col=4,
                            out_file=None):
    """
    Filters an "input norm"-formatted file given
    log2 fold change and log10 pvalue thresholds.
    See data/input_norm_bed.bed file for an example.

    Parameters
    ----------
    file_name : basename

    l10p : float
    l2fc : float
    l10p_col : int
        0-based int index of the column where l10p is described (default 3)
    l2fc_col : int
        0-based int index of the column where l2fc is described (default 4)
    out_file : basename
        output file name to write filtered bed (default None)

    Returns
    -------
    filtered : pandas.DataFrame()

    """
    df = pd.read_table(fn, header=None)
    filtered = df[(df[l2fc_col] >= l2fc) & (df[l10p_col] >= l10p)]
    if out_file is not None and filtered.shape[0] > 0:
        filtered.to_csv(out_file, sep='\t', header=False, index=False)
    return filtered


def filter_input_norm_as_bt(file_name, pval, l2fc, l10p_col=3, l2fc_col=4,
                            out_file=None):
    """
    Filters an "input norm"-formatted file given
    log2 fold change and log10 pvalue thresholds.
    See data/input_norm_bed.bed file for an example.

    Parameters
    ----------
    file_name : basename
    l10p : float
    l2fc : float
    l10p_col : int
        0-based int index of the column where l10p is described
    l2fc_col : int
        0-based int index of the column where l2fc is described
    out_file : basename

    Returns
    -------
    filtered : pybedtools.BedTool()

    """
    try:
        bedtool = pybedtools.BedTool(file_name)

        filter_data_inst = functools.partial(
            filter_data, pval=pval, l2fc=l2fc,
            l10p_col=l10p_col, l2fc_col=l2fc_col,
        )

        bedtool = bedtool.filter(filter_data_inst)

        if out_file is not None:
            bedtool.saveas(out_file)

        return bedtool

    except Exception as e:
        print(e, file_name)
        return 1


def filter_data(interval, l10p, l2fc, l10p_col, l2fc_col):
    """
    col4 is -log10 p-val
    col5 is -log2 fold enrichment

    Expects the standard input norm file format.

    Parameters
    ----------
    interval : pybedtools.Interval
    l2fc : float
    l10p : float

    Returns
    -------

    """

    return (float(interval[l10p_col]) >= l10p) and (float(interval[l2fc_col]) >= l2fc)


def bed6_to_bed8(interval):
    """
    Basically appends the start/stop fields to 'thickStart/thickStop' fields
    Turns BED6 into BED8 (formerly called: make_clipper_ish)

    Parameters
    ----------
    interval : pybedtools.Interval

    Returns
    -------

    """
    interval.name = interval[7]
    interval[6] = interval.start
    interval[7] = interval.stop

    return interval


def return_region_eric(row):
    """
    Given a row of a inputnormed bedfile, return region
    Row must be in the same format as a line in Eric's
    *.annotated file.

    """
    try:
        if row['annotation'] == 'intergenic':
            return 'intergenic'
        region = row['annotation'].split('|')[0]

        return region
    except Exception as e:
        print(e, row)

def get_cumulative_sum_counts(wd, l10p, l2fc, l10p_col=3, l2fc_col=4,
                          out_dir=None, suffix='.annotated',
                          format="eric", regions=REGIONS):
    """
    Returns a dataframe of the cumulative fraction of events within each
    region.

    Parameters
    ----------
    wd : string
        directory where the input_norm output is kept
        (where to look for .annotated files)
    out_dir : basestring
        directory where filtered input norm outputs are to be written.
    l10p : float
        log10 p value threshold
    l2fc : float
        log2 fold change threshold
    l10p_col : int
        0-based int index of the column where l10p is described (default 3)
    l2fc_col : int
        0-based int index of the column where l2fc is described (default 4)
    suffix : basestring
        suffix to grep for in wd (default ".annotated")
    format : basestring
        either 'eric' or 'brian' describing which annotation pipeline was used.
        default 'eric'
    regions : list
        list of regions to return

    Returns
    _______
    df : pandas.DataFrame()
        dataframe of the cumualtive fraction of peaks within each region


    """
    df = get_counts(
        wd, l10p, l2fc, l10p_col, l2fc_col,
        out_dir, suffix,
        format, regions
    )

    dfdiv = df / df.sum()
    cumsum_events = dfdiv.cumsum()
    return cumsum_events

def get_counts(wd, l10p, l2fc, l10p_col, l2fc_col,
               out_dir, suffix, format, regions):
    """
    Returns the number of peak counts for all regions
    annotated by eric's pipeline. Gathers all files in 'wd' with 'suffix'
    using glob and filters using l2fc and l10p parameters. If out_dir is not
    None, save these filtered BED files to directory.

    Parameters
    ----------
    wd : string
        directory where the input_norm output is kept
        (where to look for .annotated files)
    out_dir : basestring
        directory where filtered input norm outputs are to be written.
    l10p : float
        log10 p value threshold
    l2fc : float
        log2 fold change threshold
    l10p_col : int
        0-based int index of the column where l10p is described (default 3)
    l2fc_col : int
        0-based int index of the column where l2fc is described (default 4)
    suffix : basestring
        suffix to grep for in wd (default ".annotated")
    format : basestring
        either 'eric' or 'brian' describing which annotation pipeline was used.
        default 'eric'
    regions : list
        list of regions to return

    Returns
    _______
    df : pandas.DataFrame()
        dataframe of the sum of peaks within each region

    """
    samples = {}

    for f in glob.glob(os.path.join(wd, '*{}'.format(suffix))):
        basename = os.path.basename(f)
        if out_dir is not None:
            out_file = os.path.join(
                out_dir,
                basename.replace(
                    '{}'.format(suffix),
                    '{}.filtered-p{}-f{}'.format(
                        suffix, l10p, l2fc
                    )
                ),
            )
        else:
            out_file = None
        df = filter_input_norm_as_df(f, l10p, l2fc, l10p_col, l2fc_col, out_file)


        samples[basename] = {}
        if format == 'eric':
            df.columns = ANNOTATED_BED_HEADERS_ERIC
            df['region'] = df.apply(return_region_eric, axis=1)
        elif format == 'brian':
            pass  # i already return this as a separate field, no need to parse

        for key, value in df['region'].value_counts().iteritems():
            samples[basename][key] = value
        for region in regions:
            if region not in samples[basename]:
                samples[basename][region] = 0
    return pd.DataFrame(samples)
